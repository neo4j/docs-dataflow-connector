= Create a job specification file

tag::intro[]

The job configuration file instructs Dataflow on how to run the import (where to source the data from, how to map it into Neo4j, etc).

It consists of a JSON object with four sections:

- `config` -- Global flags affecting how the import is performed (optional)
- `sources` -- Data source definitions (relational)
- `targets` -- Data target definitions (graph: nodes/relationships)
- `actions` -- Pre/Post-load actions (optional)

.Job specification JSON skeleton
[source, JSON]
----
{
  "config": { ... },
  "sources": [
    { ... }
  ],
  "targets": [
    { ... }
  ],
  "actions": [
    { ... }
  ]
}
----

At a high level, the job fetches data from `sources` and transforms/imports them into the `targets`.

end::intro[]


tag::full-example[]

[#full-example]
== A full example

Here below is an example job specification file that works out of the box to import the publicly-available `movies` dataset.

The next sections break it down and provide in-context information for each part.
We recommend reading this guide side by side with the job specification example.

end::full-example[]


tag::configuration[]

[#configuration]
== Configuration

The `config` object contains global configuration for the import job.
All settings have a default, so you don't need to specify them unless you wish to alter them.

.Configuration settings and their defaults
[source, JSON]
----
"config": {
  "reset_db": false,
  "index_all_properties": false,
  "node_write_batch_size": 5000,
  "edge_write_batch_size": 1000,
  "custom_query_batch_size": 1000,
  "node_write_parallelism": 10,
  "edge_write_parallelism": 1,
  "custom_query_parallelism": 1
}
----

- `reset_db` (bool) -- Whether to clear the target database before importing.
Deletes data, indexes, and constraints.
- `index_all_properties` (bool) -- Whether to create indexes for all properties. See link:https://neo4j.com/docs/cypher-manual/current/indexes/search-performance-indexes/overview/[Cypher -> Search-performance indexes].
- `node_write_batch_size` (int) -- Number of nodes to be processed for each transaction.
- `edge_write_batch_size` (int) -- Number of relationships to be processed for each transaction.
- `custom_query_batch_size` (int) -- Number of rows to be processed for each custom query.
- `node_write_parallelism` (int) -- Number of max concurrent transactions for node targets.
- `edge_write_parallelism` (int) -- Number of max concurrent transactions for relationship targets. Values higher than `1` should be set with care, as they may result in deadlocks.
- `custom_query_parallelism` (int) -- Number of max concurrent transactions for custom query targets. Values higher than `1` should be set with care, as they may result in deadlocks.

end::configuration[]


tag::targets[]

[#targets]
== Targets

The `targets` section contains the definitions of the graph entities that will result from the import.

Neo4j represents objects with link:https://neo4j.com/docs/getting-started/appendix/graphdb-concepts/#graphdb-node[nodes] (ex. `movies`, `people`) and connects them with link:https://neo4j.com/docs/getting-started/appendix/graphdb-concepts/#graphdb-relationship[relationships] (ex. `ACTED_IN`, `DIRECTED`).
Each object in the targets section will generate a corresponding entity (node or relationship) in Neo4j drawing data from a source.
It is also possible to run custom Cypher queries.

.Targets specification skeleton
[source, JSON]
----
"targets": {
  "nodes": [ ... ],
  "relationships": [ ... ],
  "queries": [ ... ]
}
----

By default, **you do not have to think about dependencies between nodes and relationships**, as the importer compiles a tree of dependencies that ensures requirements for each target are fulfilled ahead of its import.
It is however possible to alter the default behavior and customize the ordering of targets.


[#node-objects]
=== Node objects

Node entities must be grouped in a list keyed `nodes` inside the `targets` object.

.Node targets specification skeleton
[source, JSON]
----
"targets": {
  "nodes": [
    { <nodeSpec1> },
    { <nodeSpec2> },
    ...
  ]
}
----


[#node-compulsory-fields]
==== Compulsory fields

Each node object must at minimum have attributes `source`, `name`, `labels`, and `properties`.

[source, json]
----
{
  "source": "<sourceName>",
  "name": "<targetName>",
  "labels": ["<label1>", "<label2>", ...],
  "properties": [
    {
      "source_field": "<bigqueryColumnName>",
      "target_field": "<neo4jPropertyName>",
      "target_property_type": "<neo4jPropertyType>"
    },
    { <propertyObj2> },
    ...
  ],
}
----

- `source` (string) -- The name of the source this target should draw data from. Should match one of the names from the `sources` objects.
- `name` (string) -- A human-friendly name for the target (unique among all names; no spaces allowed).
- `labels` (list of strings) -- link:https://medium.com/neo4j/graph-modeling-labels-71775ff7d121[Labels] to mark the nodes with.
- `properties` (list of objects) -- Mapping between source columns and node properties. +
Valid values for `target_property_type` are: `boolean`, `byte_array` (assumes base64 encoding), `date`, `duration`, `float`, `integer`, `local_date`, `local_datetime`, `local_time`, `point`, `string`, `zoned_datetime`, `zoned_time`.
{target_property_type-valid-values-extra}


[#node-schema]
==== Schema definition

You may create link:https://neo4j.com/docs/cypher-manual/current/indexes/[indexes] and link:https://neo4j.com/docs/cypher-manual/current/constraints/[constraints] on the imported nodes through the `schema` object.
The schema setup is equivalent to manually running the relevant `CREATE INDEX/CONSTRAINT` commands, except they are run automatically ahead of import for each entity type.

[TIP]
If the global config `index_all_properties` is set to `true`, all properties will get range indexes created already. (or?)

.Node target schema definition and their defaults
[source, json]
----
{
  ...
  "schema": {
    "enable_type_constraints": true,  // works?
    "key_constraints": [
      {
        "name": "<constraintName>",
        "label": "<label>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "unique_constraints": [
      {
        "name": "<constraintName>",
        "label": "<label>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "existence_constraints": [
      {
        "name": "<constraintName>",
        "label": "<label>",
        "property": "<neo4jPropertyName>"
      }
    ],
    "range_indexes": [
      {
        "name": "<indexName>",
        "label": "<label>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
      }
    ],
    "text_indexes": [
      {
        "name": "<indexName>",
        "label": "<label>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ],
    "point_indexes": [
      {
        "name": "<indexName>",
        "label": "<label>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ],
    "fulltext_indexes": [
      {
        "name": "<indexName>",
        "labels": ["label1", "label2", ...],
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "vector_indexes": [
      {
        "name": "<indexName>",
        "label": "<label>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ]
  }
}
----

Where the attributes for each object are:

- `name` (string) -- The name of the index or constraint to be created in Neo4j.
- `label` (string) or `labels` (list of strings) -- The label(s) on which the index or constraint should be enforced upon.
- `property` (string) or `properties` (list of strings) -- The property(s) on which the index or constraint should be enforced upon.
- `options` (object) -- The options with which the index or constraint should be created with (refer to the individual pages for each link:https://neo4j.com/docs/cypher-manual/current/indexes/[index] and link:https://neo4j.com/docs/cypher-manual/current/constraints/[constraint] type). When present, it is optional, except for vector indexes where it is mandatory.

[WARNING]
**Source data must not have null values for `key_constraints` columns**, or they will clash with the node key constraint.
If the source is not clean in this respect, think of cleaning it upfront in the related `source.query` field by excluding all rows that wouldn't fulfill the constraints (ex. `WHERE person_tmbdId IS NOT NULL`).
Alternatively, use the `where` attribute in a xref:source-transformations[source transformation].

[IMPORTANT]
The options `key_constraints` and `unique_constraints` require Neo4j/Aura Enterprise Edition, and do not have any effect when run against a Neo4j Community Edition installation.


[#node-config]
==== Configuration

.Node target config options and their defaults
[source, JSON]
----
{
  ...
  "active": true,
  "write_mode": "merge",
  "source_transformations": {
    "enable_grouping": true  // is this on by defult?
  },
  "depends_on": ["<dependencyTargetName1>", "<dependencyTargetName2>", ...]
}
----

- `active` (bool) -- Whether the target should be included in the import.
- `write_mode` (string) -- The creation mode in Neo4j. Either `create` or `merge` (default). See link:https://neo4j.com/docs/cypher-manual/current/clauses/create/[`CREATE`] and link:https://neo4j.com/docs/cypher-manual/current/clauses/merge/[`MERGE`] for info on the Cypher clauses behavior.
- `source_transformations` (object) -- If `enable_grouping` is set to `true`, the import will SQL `GROUP BY` on all fields specified in `key_constraints` and `properties`. If set to `false`, any duplicate data in the source will be pushed into Neo4j, potentially raising constraints errors or making insertion less efficient. The object can also contain aggregation functions and further fields, see xref:source-transformations[].
- `depends_on` (list of strings) -- The `name` of the target(s) that should execute _before_ the current one.


[#node-example]
==== Example

.A node object example for import of `Person` nodes
[source, json]
----
{
  "source": "persons",
  "name": "Person",
  "labels": [ "Person" ],
  "properties": [
    {
      "source_field": "person_tmdbId",
      "target_field": "id",
      "target_property_type": "string"
    },
    {
      "source_field": "name",
      "target_field": "name",
      "target_property_type": "string"
    },
    {
      "source_field": "bornIn",
      "target_field": "bornLocation",
      "target_property_type": "string"
    },
    {
      "source_field": "born",
      "target_field": "bornDate",
      "target_property_type": "string"
    },
    {
      "source_field": "died",
      "target_field": "diedDate",
      "target_property_type": "string"
    }
  ],
  "schema": {
    "key_constraints": [
      {
        "name": "personIdKey",
        "label": "Person",
        "properties": ["id"]
      }
    ],
    "unique_constraints": [
      {
        "name": "personNameUnique",
        "label": "Person",
        "properties": ["name"]
      }
    ]
  },
  "transform": {  // needed?
    "group": true
  }
}
----

'''


[#relationship-objects]
=== Relationship objects

Relationship entities must be grouped in a list keyed `relationships` inside the `targets` object.

.Relationship targets specification skeleton
[source, JSON]
----
"targets": {
  ...
  "relationships": [
    { <relationshipSpec1> },
    { <relationshipSpec2> },
    ...
  ]
}
----


[#relationship-compulsory-fields]
==== Compulsory fields

Each relationship object must at minimum have attributes `source`, `name`, and `type`.

It must also contain information about which node targets the relationship links together. You provide this through a combination of `start_node`/`start_node_reference` and `end_node`/`end_node_reference`. (?)

[source, json]
----
{
  "source": "<sourceName>",
  "name": "<targetName>",
  "type": "<relationshipType>",
  "start_node_reference": "<nodeTargetName>",  // or "start_node": { nodeObj },
  "end_node_reference": "<nodeTargetName>"  // or "end_node": { nodeObj }
}
----

- `source` (string) -- The name of the source this target should draw data from. Should match one of the names from the `sources` objects.
- `name` (string) -- A human-friendly name for the target (unique among all names; no spaces allowed).
- `type` (string) -- link:https://neo4j.com/docs/getting-started/appendix/graphdb-concepts/#graphdb-relationship-type[Type] to assign to the relationship.
- `start_node_reference` (string) -- The name of the node target that acts as _start_ for the relationship (`start_node` can play the same role, except it takes a xref:node-objects[full node object]).
- `end_node_reference` (string) -- The name of the node target that acts as _end_ for the relationship (`end_node` can play the same role, except it takes a xref:node-objects[full node object]).

[IMPORTANT]
====
`keys`, `unique` and `mandatory` options require Aura or Neo4j Enterprise Edition, and will not have any effect when run against a Neo4j Community Edition installation.
====


[#relationship-properties]
==== Properties

Relationships may also map source columns as properties.

[source, json, role=nocollapse]
----
{
  ...
  "properties": [
    {
      "source_field": "<bigqueryColumnName>",
      "target_field": "<neo4jPropertyName>",
      "target_property_type": "<neo4jPropertyType>"
    },
    { <propertyObj2> },
    ...
  ]
}
----

- `properties` (list of objects) -- Mapping between source columns and relationship properties. +
Valid values for `target_property_type` are: `boolean`, `byte_array` (assumes base64 encoding), `date`, `duration`, `float`, `integer`, `local_date`, `local_datetime`, `local_time`, `point`, `string`, `zoned_datetime`, `zoned_time`.
{target_property_type-valid-values-extra}


[#relationship-schema]
==== Schema definition

You may create link:https://neo4j.com/docs/cypher-manual/current/indexes/[indexes] and link:https://neo4j.com/docs/cypher-manual/current/constraints/[constraints] on the imported relationships through the `schema` object.
The schema setup is equivalent to manually running the relevant `CREATE INDEX/CONSTRAINT` commands, except they are run automatically ahead of import for each relationship type.

[TIP]
If the global config `index_all_properties` is set to `true`, all properties will get range indexes created already. (or?)

.Relationship target schema definition and their defaults
[source, json]
----
{
  ...
  "schema": {
    "enable_type_constraints": true,  // works?
    "key_constraints": [
      {
        "name": "<constraintName>",
        "type": "<relationshipType>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "unique_constraints": [
      {
        "name": "<constraintName>",
        "type": "<relationshipType>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "existence_constraints": [
      {
        "name": "<constraintName>",
        "type": "<relationshipType>",
        "property": "<neo4jPropertyName>"
      }
    ],
    "range_indexes": [
      {
        "name": "<indexName>",
        "type": "<relationshipType>",
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
      }
    ],
    "text_indexes": [
      {
        "name": "<indexName>",
        "type": "<relationshipType>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ],
    "point_indexes": [
      {
        "name": "<indexName>",
        "type": "<relationshipType>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ],
    "fulltext_indexes": [
      {
        "name": "<indexName>",
        "types": ["<relationshipType1>", "<relationshipType2>", ...],
        "properties": ["<neo4jPropertyName1>", "<neo4jPropertyName2>", ...],
        "options": {}
      }
    ],
    "vector_indexes": [
      {
        "name": "<indexName>",
        "type": "<relationshipType>",
        "property": "<neo4jPropertyName>",
        "options": {}
      }
    ]
  }
}
----

Where the attributes for each object are:

- `name` (string) -- The name of the index or constraint to be created in Neo4j.
- `type` (string) or `types` (list of strings) -- The type(s) on which the index or constraint should be enforced upon.
- `property` (string) or `properties` (list of strings) -- The property(s) on which the index or constraint should be enforced upon.
- `options` (object) -- The options with which the index or constraint should be created with (refer to the individual pages for each link:https://neo4j.com/docs/cypher-manual/current/indexes/[index] and link:https://neo4j.com/docs/cypher-manual/current/constraints/[constraint] type). When present, it is optional, except for vector indexes where it is mandatory.

[WARNING]
**Source data must not have null values for `key_constraints` columns**, or they will clash with the relationship key constraint.
If the source is not clean in this respect, think of cleaning it upfront in the related `source.query` field by excluding all rows that wouldn't fulfill the constraints (ex. `WHERE person_tmbdId IS NOT NULL`).
Alternatively, use the `where` attribute in a xref:source-transformations[source transformation].

[IMPORTANT]
The options `key_constraints` and `unique_constraints` require Neo4j/Aura Enterprise Edition, and do not have any effect when run against a Neo4j Community Edition installation.


[#relationship-config]
==== Configuration

.Relationship target config options and their defaults
[source, JSON]
----
{
  ...
  "active": true,
  "node_match_mode": "merge",
  "write_mode": "merge",
  "source_transformations": {
    "enable_grouping": true  // is this on by defult?
  },
  "depends_on": ["<dependencyTargetName1>", "<dependencyTargetName2>", ...]
}
----

- `active` (bool) -- Whether the target should be included in the import.
- `node_match_mode` (string) -- What Cypher clause to use to fetch the source/end nodes ahead of creating a relationship between them. Valid values are `create`, `match`, or `merge` (default), respectively resulting in the Cypher clauses link:https://neo4j.com/docs/cypher-manual/current/clauses/create/[`CREATE`], link:https://neo4j.com/docs/cypher-manual/current/clauses/match/[`MATCH`], and link:https://neo4j.com/docs/cypher-manual/current/clauses/merge/[`MERGE`].
- `write_mode` (string) -- The creation mode in Neo4j. Either `create` or `merge` (default). See link:https://neo4j.com/docs/cypher-manual/current/clauses/create/[`CREATE`] and link:https://neo4j.com/docs/cypher-manual/current/clauses/merge/[`MERGE`] for info on the Cypher clauses behavior.
- `source_transformations` (object) -- If `enable_grouping` is set to `true`, the import will SQL `GROUP BY` on all fields specified in `key_constraints` and `properties`. If set to `false`, any duplicate data in the source will be pushed into Neo4j, potentially raising constraints errors or making insertion less efficient. The object can also contain aggregation functions and further fields, see xref:source-transformations[].
- `depends_on` (list of strings) -- The `name` of the target(s) that should execute _before_ the current one.


[#relationship-example]
==== Example

.A relationship object example for import of `ACTED_IN` relationships
[source, json]
----
{
  "source": "acted_in",
  "name": "Acted_in",
  "type": "ACTED_IN",
  "start_node_reference": "Persons",
  "end_node_reference": "Movies",
  "properties": [
    {
      "source_field": "role",
      "target_field": "role",
      "target_property_type": "string"
    }
  ],
  "schema": { },
  "transform": {  // needed?
    "group": true
  }
}
----

'''


[#query-objects]
=== Custom query objects

Custom query targets are useful when the import requires a complex query that does not easily fit into the node/relationship targets format.
Query targets receive batches of rows through the variable `$rows`.

Custom queries must be grouped in a list keyed `queries` inside the `targets` object.

.Query targets specification skeleton
[source, JSON]
----
"targets": {
  ...
  "queries": [
    { <querySpec1> },
    { <querySpec2> },
    ...
  ]
}
----

[WARNING]
Do not use custom queries to run Cypher that does not directly depend on a source; use xref:_prepost_load_actions[actions] instead.
One-off queries, especially if not idempotent, are not fit to use in custom query targets.
The reason for this is that queries from targets are run in batches, so a custom query may be run several times depending on the number of `$rows` batches extracted from the source.


[#query-compulsory-fields]
==== Compulsory fields

Each relationship object must at minimum have attributes `source`, `name`, and `query`.

It must also contain information on what types of nodes the relationship links together. You provide this through a combination of `start_node`/`start_node_reference` and `end_node`/`end_node_reference`.

[source, json]
----
{
  "source": "<sourceName>",
  "name": "<targetName>",
  "query": "<cypherQuery>"
}
----

- `source` (string) -- The name of the source this target should draw data from. Should match one of the names from the `sources` objects.
- `name` (string) -- A human-friendly name for the target (unique among all names; no spaces allowed).
- `query` (string) -- A Cypher query. Data from the source is available as a list in the parameter `$rows`.


[#query-config]
==== Configuration

.Query target config options and their defaults
[source, JSON]
----
{
  ...
  "active": true,
  "depends_on": ["<dependencyTargetName1>", "<dependencyTargetName2>", ...]
}
----

- `active` (bool) -- Whether the target should be included in the import.
- `depends_on` (list of strings) -- The `name` of the target(s) that should execute _before_ the current one.


[#query-example]
==== Example

.A query object example for import of `Person` nodes and setting a date on creation
[source, JSON]
----
{
  "custom_query": {
    "name": "Person nodes",
    "source": "persons",
    "query": "UNWIND $rows AS row WHERE row.person_tmdbId IS NOT NULL MERGE (p:Person {id: row.person_tmdbId, name: row.name, born_in: row.bornIn, born: date(row.born), died: date(row.died)}) ON CREATE SET p.created_time=datetime()"
  }
}
----

end::targets[]


tag::transformations[]

[#source-transformations]
== Source transformations

Each target can optionally have a `source_transformation` attribute containing aggregation functions. This can be useful to extract higher-level dimensions from a more granular source. Aggregations result in extra fields that become available for import into Neo4j.

[source, json, role=nocollapse]
----
"source_transformations": {
  "enable_grouping": true,
  "aggregations": [ {
    "expression": "",
    "field_name": ""
   },
   { aggregationObj2 }, ...
  ],
  "limit": -1,
  "where": "",
  "order_by": [
    {
      "expression": "",
      "order": "<asc/desc>"
    },
    { orderObj2 }, ...
  ],
}
----

- `enable_grouping` (bool) -- Must be `true` for `aggregations`/`where` to work. ?
- `aggregations` (list of objects) -- Aggregations are specified as SQL queries in the `expression` attribute, and the result is available as a source column under the name specified in `field_name`.
- `limit` (int) -- Caps the number of source rows that are considered for import (defaults to no limit, encoded as `-1`).
- `where` (string) -- Filters out source data prior to import (with an SQL `WHERE` clause format).
- `order_by` (list of objects) -- Enforces ordering on the source. What shape should expression have?

[#transformation-example]
=== Example
.A transformation object example on a fictitious data set
[source, json]
----
{
  "enable_grouping": true,
  "aggregations": [
    {
      "expression": "SUM(unit_price*quantity)",
      "field_name": "total_amount_sold"
    },
    {
      "expression": "SUM(quantity)",
      "field_name": "total_quantity_sold"
    }
  ],
  "limit": 50,
  "where": "sourceId IS NOT NULL"
}
----

end::transformations[]


tag::actions[]

[#actions]
== Pre/Post load actions

The `actions` section contains commands that can be run before or after specific steps of the import process.
You may for example submit HTTP requests when steps complete, execute SQL queries on the source, or run Cypher statements on the Neo4j target instance.

.Actions specification skeleton
[source, JSON]
----
  ...
  "actions": [
    { <actionSpec1> },
    { <actionSpec2> },
    ...
  ]
----

Each action object must at minimum have the attribute `name`, `type`, and `stage`.
Further attributes depend on the action type.

[.tabbed-example]
====
[.include-with-HTTP-action]
=====

[source, json]
----
{
  "type": "http",
  "name": "<actionName>",
  "stage": "<stageName>",
  "method": "<get/post>",
  "url": "<targetUrl>",
  "headers": {}
}
----

- `type` (string) -- The action type.
- `name` (string) --  A human-friendly name for the action (unique among all names; no spaces allowed).
- `stage` (string) -- At what point of the import the action should run. Valid values are: `start`, `post_sources`, `pre_nodes`, `post_nodes`, `pre_relationships`, `post_relationships`, `pre_queries`, `post_queries`, `end`.
- `method` (string) -- The HTTP method; either `get` or `post`.
- `url` (string) -- The URL the HTTP request should target.
- `headers` (object, optional) -- Request headers.

=====

[.include-with-Cypher-action]
=====

[source, json]
----
{
  "type": "cypher",
  "name": "<actionName>",
  "stage": "<stageName>",
  "query": "<cypherQuery>",
  "execution_mode": "<transaction/autocommit>"
}
----

- `type` (string) -- The action type.
- `name` (string) --  A human-friendly name for the action (unique among all names; no spaces allowed).
- `stage` (string) -- At what point of the import the action should run. Valid values are: `start`, `post_sources`, `pre_nodes`, `post_nodes`, `pre_relationships`, `post_relationships`, `pre_queries`, `post_queries`, `end`.
- `query` (string) -- The Cypher query to run.
- `execution_mode` (string, optional) -- Under what mode the query should be executed.

=====

[.include-with-BigQuery-action]
=====

[source, json]
----
{
  "type": "bigquery",
  "name": "<actionName>",
  "stage": "<stageName>",
  "sql": "<sqlQuery>"
}
----

- `type` (string) -- The action type.
- `name` (string) --  A human-friendly name for the action (unique among all names; no spaces allowed).
- `stage` (string) -- At what point of the import the action should run. Valid values are: `start`, `post_sources`, `pre_nodes`, `post_nodes`, `pre_relationships`, `post_relationships`, `pre_queries`, `post_queries`, `end`.
- `sql` (string) -- The SQL query to run.

=====

====


[#actions-example]
=== Examples




end::actions[]


tag::variables[]

[#variables]
== Variables

Key-values can be supplied in Dataflow to replace `$` delimited tokens in SQL queries, URLs, custom queries, or action options/headers (?).
You can provide parameters in the `Options JSON` field when creating the Dataflow job, as a JSON object.

Variables must be prefixed by the `$` symbol (ex. `$limit`), and may be used in job specification files and in `readQuery` or `inputFilePattern` (source URI) xref:cli.adoc[command-line] parameters.

end::variables[]
